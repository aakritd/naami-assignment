# NAAMI ASSIGNMENT 2 - ML CLASSIFICATION ASSIGNMENT

The objective of this assignment was to build and evaluate machine learning models for a multi-class classification problem using tabular data. The process began with data preprocessing, where non-finite records were dropped to ensure data quality. The dataset was analyzed for class balance, and standardization was applied to remove any bias in feature scales. Two types of datasets were created: one with all 3236 original features (used for Random Forest and XGBoost), and another reduced to 100 features using SelectKBest with ANOVA F-statistic (used for Logistic Regression).

Three machine learning models were implemented: Logistic Regression, Random Forest, and XGBoost. The Logistic Regression model served as a simple baseline and was trained on the reduced feature set. It was configured with class weighting to handle imbalance and a higher iteration limit to ensure convergence. Random Forest, an ensemble method capable of handling high-dimensional data, was trained on the full feature set without prior feature selection. It utilized multiple decision trees to improve robustness and generalization. XGBoost, a powerful gradient boosting algorithm, was also trained on the complete dataset and configured to optimize log-loss during training.

For each model, the training phase involved fitting the model to the prepared training data and then generating predictions and class probabilities on the test set. Throughout the process, standard libraries such as NumPy, Pandas, Scikit-learn, and XGBoost were used for data handling, model training, and evaluation. The final predictions on the blinded test set were saved in CSV format for submission.
